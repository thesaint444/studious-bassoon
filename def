def generate_response(input_text):
    input_tokens = tokenizer.encode(input_text, return_tensors="pt")
    output_tokens = model.generate(input_tokens, max_length=200, pad_token_id=tokenizer.eos_token_id)
    output_text = tokenizer.decode(output_tokens[:, input_tokens.shape[-1]:][0], skip_special_tokens=True)
    return output_text
